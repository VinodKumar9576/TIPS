{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Statistical Tests 22/04.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OoMNrMsqaK3_",
        "F2jR_m3qa6ve"
      ],
      "authorship_tag": "ABX9TyNxZNZCmP7Yz3ha1uvoFKvQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5fv5airdD9J",
        "colab_type": "text",
        "badge": true,
        "repo_name": "VinodKumar9576/TIPS",
        "branch": "master",
        "nb_path": "Tips/Statistical Tests 22 04.ipynb",
        "comment": "This badge cell was added by colab-badge-action"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinodKumar9576/TIPS/blob/master/Tips/Statistical Tests 22 04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j8dirqdSOwW",
        "colab_type": "text"
      },
      "source": [
        "https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/\n",
        "<br>\n",
        "https://machinelearningmastery.com/statistical-hypothesis-tests/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKhh5h0wXAG3",
        "colab_type": "text"
      },
      "source": [
        "* Comparing ML methods and selecting a final model is a common opearation in applied ML.\n",
        "* Models are commonly evaluated using resampling methods like k-fold CV from which mean evaluation scores are calculated and compared directly.\n",
        "* Above is simple approach but can misleading, as whether the difference between mean evaluation scores is **`real`** or the result of stastical **`fluke`**.\n",
        "* **`Statistical significance test`** are designed to detect this problem and quantify the likelihood of samples of evaluation scores given the assumption that they were drawn from same distribution.\n",
        "* **`Statistical hypothesis testing`** can improve both confidence in the interpretation and presentation of results during model selection.\n",
        "\n",
        "Lets see the importance and challenge of selecting a statistical hypothesis test for comparing ML models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoWXtxkUY8Ua",
        "colab_type": "text"
      },
      "source": [
        "#Problem of model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lHEjS2aZBrr",
        "colab_type": "text"
      },
      "source": [
        "* Given the evaluation of two ML methods on a dataset, which model do you choose? --- We choose the model with best evaluation score on unseen dataset.\n",
        "* Evaluation can be `maximum accuracy` on classification or `minimum error` in regression.\n",
        "* The process of selecting best model tells us how much we rely on the evaluation metric used on each model.\n",
        "* Or is the evaluation score difference b/w models is real or due to statistical chance?\n",
        "* Hypothesis testing can answer this question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoMNrMsqaK3_",
        "colab_type": "text"
      },
      "source": [
        "#Statistical Hypothesis Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVI39_KyeLIk",
        "colab_type": "text"
      },
      "source": [
        "* Assumption in Hypothesis testing is **`null hypothesis`**.\n",
        "* We reject or accept null hypothesis based on statisstical measures calculated.\n",
        "* In case of selecting models based on the evaluation score, we need to know whether the difference is real:<br>\n",
        "* **Null Hypothesis** : The diff is due to statistcal chance.\n",
        "  * Case - I:\n",
        "    * Result of test : There's insufficient evidence to reject the null hypothesis.\n",
        "    * Outcome : Diff is likely due to **statistical chance**.\n",
        "  * Case - II\n",
        "    * Result : There's sufficient evidence to reject the null hypothesis.\n",
        "    * Outcome : Diff is likely due to difference in models.\n",
        "* **Results of test are probabilistic** : It is possible to correctly interpret the result and for the result to be wrong with a **`type I or type II`** error.<br> A flase positive or false negative finding.(Actual F, predicted T or actual T, predicted F)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9_H8F1WhbKf",
        "colab_type": "text"
      },
      "source": [
        "Factors that impact the types of statistical tests to be used for comparing ML models:\n",
        "* **Evaluation metric** : Chosen according to the model. **`Accuracy`** - classification, **`mean absolute error`** - regression which will limit the type of test that can be used.\n",
        "* **Repeated Estimates** : A sample of evaluation metric scores is required to calculate statistics. Repeated training and testing a given model on same or different data will impact the type of test that can be used.\n",
        "* **Distribution of Estimates** : The sample of evaluation scores will have a distribution (Gaussian or any other). This will determine whether **`parametric`** or **`non - parametric`** test can be used.\n",
        "* **Central Tendancy** : Model evaluation will often compared using a summary statistic such as a **`mean or median`**, depending on the distribution of evaluated scores. The test may or may not take this directly into account.\n",
        "\n",
        "Results of a statistical test are often a **`test statistic`** and a **`p-value`**. Both can be used in the presentation of results in order to quantify the level of confidence or sigficance in the diff b/w models.<br>\n",
        "This allows to make stronger decisions as part of model selection than not using statistical hypothesis tests.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI9PDkDiaVKe",
        "colab_type": "text"
      },
      "source": [
        "#Problem of choosing a Hypothesis Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsBWo5eQllu6",
        "colab_type": "text"
      },
      "source": [
        "Lets take a example for evaluating an comparing classifiers for a balanced binary classification.<br>\n",
        "* Generally:\n",
        "  * We use accuracy as evaluation metric\n",
        "  * Evaluate each model using 10-fold cross-validation\n",
        "  * Assume gaussian distribution for the sample of 10 evaluation scores\n",
        "  * We use mean of sample of evaluation scores as a summary of model's skill."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmVPsrh2aZQA",
        "colab_type": "text"
      },
      "source": [
        "#Summary of some findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9XPlKX-as6_",
        "colab_type": "text"
      },
      "source": [
        "##Use McNemar's test or 5x2 Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G-40C23az2n",
        "colab_type": "text"
      },
      "source": [
        "##Refinements on 5x2 Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2jR_m3qa6ve",
        "colab_type": "text"
      },
      "source": [
        "#Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JdJYvw7a8ef",
        "colab_type": "text"
      },
      "source": [
        "##1. Independent Data Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbhDcHSDbCge",
        "colab_type": "text"
      },
      "source": [
        "##2. Accept the Problems of 10-fold CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWQDfyoKbHQ3",
        "colab_type": "text"
      },
      "source": [
        "##2. Use McNemar's Test or 5x2 CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ejqxgArbLNJ",
        "colab_type": "text"
      },
      "source": [
        "##4. Use a Non-paramtric Paired Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BatCBUjkbXOm",
        "colab_type": "text"
      },
      "source": [
        "##5. Use Estimation Statistics Instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkXrEvYAaYus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}