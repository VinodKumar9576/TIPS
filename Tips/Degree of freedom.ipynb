{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Degree of freedom.ipynb","provenance":[],"collapsed_sections":["Bls-o4kg_DuR"],"authorship_tag":"ABX9TyNBhc8XZsT61GU5m6LZY8oF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_Bc2mN2gbvxC","colab_type":"text"},"source":["{{ badge }}"]},{"cell_type":"markdown","metadata":{"id":"foWHQzgF5OFW","colab_type":"text"},"source":["**Degree of Freedom**\n","* Used to summarize the no. of values used in the calculation of a statistic or an equation.\n","* In ML, DoF refers to no. of parameters in the model. Eg: no. of coefficients in Lr. Reg. or the number of weights in deep learning NN.\n","* Concern is that, if there are more DoF in ML, then model may overfit the training dataset.\n","* This can be overcome by using regularization terms in objective functions. Eg. L1,L2 in Log, Lr regression models.\n","* Each parameter is a separate dimension in a d-dim space."]},{"cell_type":"markdown","metadata":{"id":"2sFwYQfH6rlX","colab_type":"text"},"source":["#Degrees of Freedom in Statistics"]},{"cell_type":"markdown","metadata":{"id":"Eoz8TuNU6vae","colab_type":"text"},"source":["* In statistics, DoF is the no. of values(variables) used in calculation of a statistic.\n","* `DoF = no. of independent values - no. of statistics (method like mean,median etc)`\n","* Eg: 50 independent samples, to calculate statistic like mean.<br> DoF = 50 - 1 = 49\n","* Important in data distributions and statistical hypothesis tests."]},{"cell_type":"markdown","metadata":{"id":"nSyspqV68FY6","colab_type":"text"},"source":["#Degrees of Freedom in ML"]},{"cell_type":"markdown","metadata":{"id":"hUZLBHwi8ICQ","colab_type":"text"},"source":["* In ML, DoF refers to the no. of parameters in the model's objective function.\n","* This includes both, coefficients of model and data used in the calculation of error of the model."]},{"cell_type":"markdown","metadata":{"id":"Q1WXtR7K8dgd","colab_type":"text"},"source":["##DoF for Linear Regression Model"]},{"cell_type":"markdown","metadata":{"id":"I2aD36Ej8qDj","colab_type":"text"},"source":["* Consider a dataset that has 2 features.\n","* Two coefficients needs to be calculated for two features in linear regression.<br>\n","`ŷ = x1*β1 + x2*β2`\n","* DoF = no. of features in input data as those many coefficients we are going to calculate.\n","* DoF is an accounting of how many parameters are estimated by the model or a measure of complexity for linear regression models.\n","* DoF = No. of features when sample size > no. of features in training data."]},{"cell_type":"markdown","metadata":{"id":"IPkDOfDk-EVq","colab_type":"text"},"source":["##DoF for Linear Regression Error"]},{"cell_type":"markdown","metadata":{"id":"odx8f65q-I0S","colab_type":"text"},"source":["* Training data size also matters and impact the overall DoF for regression models. Eg: sample size 100 in training data\n","* Model error DoF = No. of samples in training data - no. of features in training data (parameters)\n","* Model error DoF = 100 - 2 = 98\n","* Each data point in training data has 1 degree of freedom."]},{"cell_type":"markdown","metadata":{"id":"Bls-o4kg_DuR","colab_type":"text"},"source":["#Total DoF for Linear Regression"]},{"cell_type":"markdown","metadata":{"id":"PHHpkAy8_GNA","colab_type":"text"},"source":["* Total DoF = sum(model Dof, model Error DoF)\n","* Lr. Regression DoF = model Dof + model Error DoF\n","* Lr. Regression DoF = 2 + 98 = 100\n","* In general DoF = No. of data points in training data set."]},{"cell_type":"markdown","metadata":{"id":"qRb3iUi9_siw","colab_type":"text"},"source":["#Negative DoF"]},{"cell_type":"markdown","metadata":{"id":"ZqOuaLbJ_wWe","colab_type":"text"},"source":["* Say, we have more features than data points of data.\n","* Model DoF = 10000 (feats)\n","* Model Error DoF = 100 (data size) - 10000 = -9900\n","* Total DoF for Lr Reg. model = 10000 + (-9900) = 100\n","* Model has DoF = 100. but has negative error DoF.\n","* A negative DoF is valid.\n","* It simply says that we have more features than we have rows of data.\n"]},{"cell_type":"markdown","metadata":{"id":"YCn2HC56BGeP","colab_type":"text"},"source":["#DoF and Overfitting"]},{"cell_type":"markdown","metadata":{"id":"z0_H2U3PBJQm","colab_type":"text"},"source":["* When there are more features than data points there's a chance for overfitting.\n","* If that's the case, then we could make the model to predict the training dataset corrctly and exactly. -- Overfitting.\n","* This is the general concern in Deep Learning NN models.\n","* Often DLNN, have many features(model weights) than samples(eg. billions of weights). These are expected to overfit based on knowledge we have from linear models.\n","* This can be overcome by selecting suitable models and regularization techniques and can have low generalization error.\n"]}]}