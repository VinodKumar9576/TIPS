{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Parallel processing.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xWuJ-Shsc4Eo","colab_type":"text"},"source":["{{ badge }}"]},{"cell_type":"markdown","metadata":{"id":"ZEngaLL8CXhW","colab_type":"text"},"source":["From somewhere in reddit\n","> The VM used for Colaboratory appears to have 13GB RAM and 2 vCPU when checking using psutil (so a n1-highmem-2 instance)\n","\n","- 2-core Xeon 2.2GHz\n","- 13GB RAM\n","- 33GB HDD\n","\n","maximum lifetime of a VM is 12 hours. Idle VMs time out after 90m"]},{"cell_type":"markdown","metadata":{"id":"YMosqhC6Jv1K","colab_type":"text"},"source":["\n","\n","1.   Define your function to apply on dataset\n","2.   Define your parallel function\n","3. Appy your function\n","\n"]},{"cell_type":"code","metadata":{"id":"PAtn7smOGb4J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585732779572,"user_tz":-330,"elapsed":1552,"user":{"displayName":"ml learning","photoUrl":"","userId":"11852164450280049527"}},"outputId":"81e4b8e7-7073-4ade-8837-7f48f7422e5d"},"source":["from psutil import *\n","\n","cpu_count()\n","# we have 2 cpu count so we can work parallely on 2 cores"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"J4DYqbIVDKrM","colab_type":"code","colab":{}},"source":["def txt2vec (df):\n","  for qstn1 in tqdm(list(df),position=0):\n","    doc1 = nlp(qstn1) #word2vec conversion using\n","    mean_vec1 = np.zeros([len(doc1),300])\n","    #making array of zeros of size of question\n","    for word1 in doc1:\n","      vec1 = word1.vector #getting the vector of each word in question\n","      #vec1 = vec1.reshape(len(vec1),1)\n","      try:\n","        idf = tfidf_vect[str(word1)]\n","      except:\n","        idf = 0\n","    \n","      mean_vec1 +=vec1*idf\n","    mean_vec1 = mean_vec1.mean(axis=0)\n","    vecs1.append(mean_vec1)\n","  \n","  return vecs1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7xhE29wKnwk","colab_type":"code","colab":{}},"source":["## Parallelizing function\n","\n","def parallelization(df, func, n_cores=4):\n","  df_split = np.array_split(df, n_cores)\n","  pool = Pool(n_cores)\n","  #applying func to each part of df\n","  df = pd.concat(pool.map(func, df_split))\n","  pool.close()\n","  pool.join()\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eR2wPmEaPo0v","colab_type":"code","colab":{}},"source":["ex = parallelization(df,txt2vec)"],"execution_count":null,"outputs":[]}]}